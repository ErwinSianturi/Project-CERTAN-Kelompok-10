{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe38b1c4-9e2f-4390-8dc7-ac2b0cbca0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential,load_model,save_model\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e105bd-4659-48d7-b0e5-a3527e4b8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Path ke folder dataset Anda\n",
    "base_dir = r\"D:\\Semester 3\\Kecerdasan Buatan (CERTAN)\\Week 16\\Proyek\\DataSet\\archive\\dataset\"\n",
    "men_dir = os.path.join(base_dir, \"MEN\")\n",
    "women_dir = os.path.join(base_dir, \"WOMAN\")\n",
    "\n",
    "# Output folder untuk subset\n",
    "output_dir_men = os.path.join(base_dir, \"MEN_subset\")\n",
    "output_dir_women = os.path.join(base_dir, \"WOMAN_subset\")\n",
    "\n",
    "# Membuat folder output jika belum ada\n",
    "os.makedirs(output_dir_men, exist_ok=True)\n",
    "os.makedirs(output_dir_women, exist_ok=True)\n",
    "\n",
    "# Fungsi untuk memilih dan menyalin gambar\n",
    "def copy_random_images(source_dir, target_dir, num_images):\n",
    "    # Daftar semua file di source_dir\n",
    "    all_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "    # Memilih file secara acak\n",
    "    selected_files = random.sample(all_files, min(num_images, len(all_files)))\n",
    "    # Menyalin file ke target_dir\n",
    "    for file in selected_files:\n",
    "        shutil.copy(os.path.join(source_dir, file), os.path.join(target_dir, file))\n",
    "\n",
    "# Membagi dataset MEN dan WOMEN masing-masing 600 gambar\n",
    "copy_random_images(men_dir, output_dir_men, 600)\n",
    "copy_random_images(women_dir, output_dir_women, 600)\n",
    "\n",
    "print(\"Proses selesai. Gambar telah dipindahkan ke folder subset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f9c92-ef16-4d22-a680-c5032193479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "      rotation_range=25,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429682e-ddf2-4fed-85be-8838b59e23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "target_size = (64, 64)\n",
    "input_shape=(64, 64, 3)\n",
    "seed=1337\n",
    "adam = 0.001\n",
    "fre= -20\n",
    "FC = 2048\n",
    "E = 1\n",
    "patience = 3\n",
    "verbose = 1\n",
    "factor = 0.50\n",
    "min_lr = 0.0001\n",
    "steps_per_epoch=256\n",
    "validation_steps=256\n",
    "epochs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707740f-d27c-4e19-bfe1-8a0b12ab7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator( rescale = 1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('../input/gender-dataset/Dataset/Train',\n",
    "                                                    batch_size =batch_size ,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    seed=seed,\n",
    "                                                    target_size = target_size )     \n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory( '../input/gender-dataset/Dataset/Validation',\n",
    "                                                          batch_size  = batch_size,\n",
    "                                                          class_mode  = 'binary',\n",
    "                                                          seed=seed,\n",
    "                                                          target_size = target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ca658-9993-4ba5-9cc1-2839b599b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG16(input_shape=input_shape,include_top=False,weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a61ca4-c058-4f6c-8e9b-237bb61b4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing Layers\n",
    "\n",
    "for layer in base_model.layers[:fre]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a57841-7f4b-46ad-a12e-a95ae4af5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Dropout(.2))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3),strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(.1))\n",
    "model.add(Conv2D(128, (3, 3),strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(.1))\n",
    "model.add(Conv2D(384, (3, 3),strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(.1))\n",
    "model.add(Conv2D(384, (3, 3),strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(.1))\n",
    "model.add(Conv2D(500, (3, 3),strides=(1,1), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2,strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(FC , activation='relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(Dense(FC , activation='relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(Dense(FC, activation='relu'))\n",
    "model.add(layers.Dropout(.2))\n",
    "model.add(Dense(E, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaaa1c6-7a44-42a2-ad0f-3f1bf8ed4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                        patience = patience,\n",
    "                        verbose = verbose ,\n",
    "                        factor = factor,\n",
    "                        min_lr = min_lr)\n",
    "\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "\n",
    "es = EarlyStopping(verbose=verbose, patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f099a-511b-41a2-ab28-3c2962786aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "hist = model.fit_generator(generator=train_generator,\n",
    "                           validation_data=validation_generator,\n",
    "                           steps_per_epoch=steps_per_epoch,\n",
    "                           validation_steps=validation_steps,\n",
    "                           epochs=epochs,\n",
    "                           callbacks=[lrd, mcp, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5b224-1902-4c35-bfc9-8d4de016e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'y', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093745d9-9e77-46fb-999e-27ab2c411194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "#  images test 1\n",
    "path_testmodel = \"../input/testmodel/test1.jpg\"\n",
    "imge = image.load_img(path_testmodel, target_size=target_size)\n",
    "X = image.img_to_array(imge)\n",
    "X = np.expand_dims(X, axis=0)\n",
    "\n",
    "images = np.vstack([X])\n",
    "classes = model.predict(images, batch_size=1)\n",
    "print(classes[0])\n",
    "if classes[0]<0.5:\n",
    "    print(\"This is a male\")\n",
    "else:\n",
    "    print( \"This  is a female\")\n",
    "plt.imshow(imge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3e35f-e2f9-44d8-b5f3-91d274db93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "#  images test 2\n",
    "path_testmodel = \"../input/testmodel/test2.jpg\"\n",
    "imge = image.load_img(path_testmodel, target_size=target_size)\n",
    "X = image.img_to_array(imge)\n",
    "X = np.expand_dims(X, axis=0)\n",
    "\n",
    "images = np.vstack([X])\n",
    "classes = model.predict(images, batch_size=1)\n",
    "print(classes[0])\n",
    "if classes[0]>0.5:\n",
    "    print(\"This is a male\")\n",
    "else:\n",
    "    print( \"This is a female\")\n",
    "plt.imshow(imge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dabfad-d00b-4375-8491-7726f2a4188d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
